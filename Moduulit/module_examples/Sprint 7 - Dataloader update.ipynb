{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work/TeamAdconsys/Tuomas/modules/\")\n",
    "from rounding import rounding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer \n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def dataloaders(path, overwrite=False, regmodel=True):\n",
    "    \"\"\"\n",
    "    Function creates dataloaders for neural networks.\n",
    "    \n",
    "    EXAMPLE HOW TO DEFINE DATALOADERS:\n",
    "    ----------------------------------\n",
    "    train_loader, test_loader, val_loader, large_test_loader = dataloaders('/home/jovyan/work/TeamAdconsys/Tuomas/NN_data/new_data', overwrite=True, regmodel=True)    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    path :\n",
    "        - Your path to train, test and validation csv-files.\n",
    "        - Example: \"/home/jovyan/work/TeamAdconsys/Tuomas/NN_data/\"\n",
    "        - Example2: \"~/work/TeamAdconsys/proj3-team-adconsys/Datat/csv\"\n",
    "        \n",
    "    overwrite : \n",
    "        - Default: False\n",
    "        - False = LammitysS values are default.\n",
    "        - True = You can define LämmitysS values for example to 70 (then set 0.7 => normalized).\n",
    "        \n",
    "    regmodel :\n",
    "        - Default: True\n",
    "        - True if you are using regression model instead of classification model.\n",
    "        - If you use classification model then set False. Then function rounds target values.\n",
    "        - If False MAKE SURE YOU HAVE IMPORT ROUNDING\n",
    "        \n",
    "\n",
    "    Returns\n",
    "    \n",
    "    -------\n",
    "    \n",
    "    Four different dataloaders.\n",
    "    \n",
    "    \"\"\"\n",
    "    start = timer()\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "    print(\"------------------ Creating Dataloaders ---------------------\")\n",
    "    print(\"-------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Jos halutaan itse määrittää lämmitykselle jokin säätöarvo ...\n",
    "    # ... esim. 0.1, 0.3 tai 0.7 niin silloin overwrite==True\n",
    "    if overwrite==True:\n",
    "        setvalue = float(input(\"Define value_LammitysS\"))\n",
    "    \n",
    "    \n",
    "    print(f\"\\nReading csv-files from {path}/\")\n",
    "    x_train = pd.read_csv(f\"{path}/X_train.csv\", header=0)\n",
    "    \n",
    "    if overwrite==True:\n",
    "        x_train['value_LammitysS'] = setvalue\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in x_train:\n",
    "        x_train = x_train.drop(columns = ['timestamp'])\n",
    "        \n",
    "    y_train = pd.read_csv(f\"{path}/y_train.csv\", header=0)\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in y_train:\n",
    "        y_train = y_train.drop(columns = ['timestamp'])\n",
    "    \n",
    "    x_test = pd.read_csv(f\"{path}/X_test.csv\", header=0)\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in x_test:\n",
    "        x_test = x_test.drop(columns = ['timestamp'])\n",
    "    \n",
    "    if overwrite==True:\n",
    "        x_test['value_LammitysS'] = setvalue\n",
    "        \n",
    "    y_test = pd.read_csv(f\"{path}/y_test.csv\", header=0)\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in y_test:\n",
    "        y_test = y_test.drop(columns = ['timestamp'])\n",
    "    \n",
    "    x_val = pd.read_csv(f\"{path}/X_val.csv\", header=0)\n",
    "    \n",
    "    if overwrite==True:\n",
    "        x_val['value_LammitysS'] = setvalue\n",
    "        \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in x_val:\n",
    "        x_val = x_val.drop(columns = ['timestamp'])\n",
    "        \n",
    "    y_val = pd.read_csv(f\"{path}/y_val.csv\", header=0)\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in y_val:\n",
    "        y_val = y_val.drop(columns = ['timestamp'])\n",
    "    \n",
    "    # Rounding target values for classification model\n",
    "    if regmodel == False:\n",
    "        print(\"\\nRounding target values for classification model\")\n",
    "        y_train = rounding(y_train)\n",
    "        y_test = rounding(y_test)\n",
    "        y_val = rounding(y_val)\n",
    "    \n",
    "    # TRAINLOADER\n",
    "    inputs_train = torch.tensor(x_train.values)\n",
    "    targets_train = torch.tensor(y_train.values)\n",
    "    targets_train = targets_train.squeeze()\n",
    "    targets_train = targets_train.type(torch.LongTensor)\n",
    "    \n",
    "    train = data_utils.TensorDataset(inputs_train, targets_train)\n",
    "    train_loader = data_utils.DataLoader(train, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # TESTLOADER\n",
    "    inputs_test = torch.tensor(x_test.values)\n",
    "    targets_test = torch.tensor(y_test.values)\n",
    "    targets_test = targets_test.squeeze()\n",
    "    targets_test = targets_test.type(torch.LongTensor)\n",
    "    \n",
    "    test = data_utils.TensorDataset(inputs_test, targets_test)\n",
    "    test_loader = data_utils.DataLoader(test, batch_size=64)\n",
    "    \n",
    "    # VALIDATIONLOADER\n",
    "    inputs_val = torch.tensor(x_val.values)\n",
    "    targets_val = torch.tensor(y_val.values)\n",
    "    targets_val = targets_val.squeeze()\n",
    "    targets_val= targets_val.type(torch.LongTensor)\n",
    "    \n",
    "    val = data_utils.TensorDataset(inputs_val, targets_val)\n",
    "    val_loader = data_utils.DataLoader(val, batch_size=64)\n",
    "    \n",
    "    # LARGE TESTLOADER (Datat yhdistetty)\n",
    "    train_y = pd.read_csv(f\"{path}/y_train.csv\")\n",
    "    train = pd.read_csv(f\"{path}/X_train.csv\")\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in train_y:\n",
    "        train_y = train_y.drop(columns = ['timestamp'])\n",
    "        \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in train:\n",
    "        train = train.drop(columns = ['timestamp'])\n",
    "    train[\"y\"] = train_y\n",
    "    train.drop_duplicates()\n",
    "    \n",
    "    test_y = pd.read_csv(f\"{path}/y_test.csv\")\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in test_y:\n",
    "        test_y = test_y.drop(columns = ['timestamp'])\n",
    "    test = pd.read_csv(f\"{path}/X_test.csv\")\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in test:\n",
    "        test = test.drop(columns = ['timestamp'])\n",
    "    test[\"y\"] = test_y\n",
    "    test.drop_duplicates()\n",
    "    \n",
    "    val_y = pd.read_csv(f\"{path}/y_val.csv\")\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in val_y:\n",
    "        val_y = val_y.drop(columns = ['timestamp'])\n",
    "    val = pd.read_csv(f\"{path}/X_val.csv\")\n",
    "    \n",
    "    # Removing timestamp column if it exists\n",
    "    if 'timestamp' in val:\n",
    "        val = val.drop(columns = ['timestamp'])\n",
    "    val[\"y\"] = val_y\n",
    "    val.drop_duplicates()\n",
    "    \n",
    "    train = train.append(test)\n",
    "    train = train.append(val)\n",
    "    train.drop_duplicates()\n",
    "    \n",
    "    train_y = train['y']\n",
    "    train = train.drop(columns=['y'])\n",
    "    \n",
    "    if overwrite==True:\n",
    "        train['value_LammitysS'] = setvalue\n",
    "        \n",
    "    large_inputs_test = torch.tensor(train.values)\n",
    "    large_targets_test = torch.tensor(train_y.values)\n",
    "    \n",
    "    large_test = data_utils.TensorDataset(large_inputs_test, large_targets_test)\n",
    "    large_test_loader = data_utils.DataLoader(large_test, batch_size=64)\n",
    "    \n",
    "    print(\"\\nDataloaders:\\ntrain_loader:\", len(train_loader), \"\\ntest_loader:\", len(test_loader),\"\\nval_loader:\", len(val_loader), \"\\nlarge_test_loader:\", len(large_test_loader))\n",
    "    \n",
    "    end = timer()\n",
    "    print(\"\\n\\nDone in\", round(end-start,2),\"seconds.\")\n",
    "    \n",
    "    return train_loader, test_loader, val_loader, large_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "------------------ Creating Dataloaders ---------------------\n",
      "-------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Define value_LammitysS 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading csv-files from /home/jovyan/work/TeamAdconsys/Tuomas/NN_data/new_data/\n",
      "\n",
      "Dataloaders:\n",
      "train_loader: 6363 \n",
      "test_loader: 1833 \n",
      "val_loader: 1837 \n",
      "large_test_loader: 10032\n",
      "\n",
      "\n",
      "Done in 6.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, val_loader, large_test_loader = dataloaders('/home/jovyan/work/TeamAdconsys/Tuomas/NN_data/new_data',overwrite=True,regmodel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
